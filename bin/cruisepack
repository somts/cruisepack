#!/usr/bin/env python3

# TODO: deal with errant symlinks; they presently cause an exception

'''cruisepack
    STS cruise data packer, in Python'''

import argparse
import hashlib
import logging
import logging.handlers
import os
import tarfile
import tempfile
import time
import sys
from json import dumps
from multiprocessing import cpu_count
from multiprocessing import Pool
from multiprocessing.dummy import Pool as DummyPool
from pathlib import Path
from zipfile import ZipFile, ZIP_BZIP2, ZIP_LZMA


class CPError(Exception):
    '''Hack our own fatal error class'''
    def __init__(self, errmsg, exception=None):
        super().__init__()
        self.errmsg = errmsg
        self.exception = exception

    def __str__(self):
        if self.exception is not None:
            return '\n\t'.join((self.errmsg, '%s' % self.exception))
        return self.errmsg


class CruisePack:
    '''Set up a class to pack cruise data'''
    TIME_DURATION_UNITS = (('week', 604800), ('day', 86400),
                           ('hour', 3600), ('min', 60), ('second', 1))

    def __init__(self):
        self.args = self.args_validate(self.args_parse())

        # Set up console logging
        self.formatter = logging.Formatter(
            '%(asctime)s %(levelname)7s: %(message)s')
        self.logger = self.logger_config()

        self.logger.info('CLI arguments:\n%s',
                         dumps(self.args.__dict__, indent=1))

        for i, srcdir in enumerate(self.args.source_dir):
            self.pack_dir(srcdir, self.args.dstlog[i],
                          self.args.dstmd5[i], self.args.dstzip[i])

    @staticmethod
    def args_parse():
        '''parse STDIN, if any'''

        parser = argparse.ArgumentParser(
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            description='''
                Build and execute a series of CLI rsync commands
                in order to synchronize data from our
                Data Acquisition Systems (DAS) to a central server.'''
        )

        parser.add_argument(
            '-s', '--source-dir',
            nargs='+',
            required=True,
            help='source directory(s) of files to archive. Multiple sources' +
            ' will create multiple destinations')
        parser.add_argument(
            '-d', '--destination-dir',
            default=None,
            nargs='+',
            help='destination directiory(s) to write arcive to. When None, ' +
            'the destination will be the parent dir of each source')
        parser.add_argument(
            '-E', '--extension',
            type=str,
            default='tar.bz2',
            choices=('tar.bz2', 'zip'),
            help='extension of target archive. NOTE: zip processing is ' +
            'in series whereas tar.bz2 is multithreaded')
        parser.add_argument(
            '-D', '--delete-after',
            action='store_true',
            help='Delete source(s) after successfully writing destination(s).')
        parser.add_argument(
            '-O', '--overwrite-destination',
            action='store_true',
            help='Overwrite destination(s), if destination(s) exist.')
        parser.add_argument(
            '-P', '--proc-count',
            default=cpu_count()*2-1,
            type=int,
            help='number of parallel md5sum jobs to run')

        return parser.parse_args()

    @staticmethod
    def args_validate(args):
        '''Validate CLI arguments'''
        if not isinstance(args.delete_after, bool):
            raise CPError

        if not isinstance(args.source_dir, list):
            raise CPError
        # Convert args to absolute path(s)
        for i, val in enumerate(args.source_dir):
            args.source_dir[i] = Path(val).absolute().__str__()

        if args.destination_dir is None:
            args.destination_dir = []
            for i in args.source_dir:
                args.destination_dir.append(
                    Path(i).parent.absolute().__str__())

        if not isinstance(args.destination_dir, list):
            raise CPError

        # Calculate destinations
        dst = []

        if len(args.destination_dir) == 1:
            for i in args.source_dir:
                dst.append(
                    Path.joinpath(Path(args.destination_dir[0]),
                                  '%s' % Path(i).name).__str__())
        elif len(args.source_dir) == len(args.destination_dir):
            for i, val in enumerate(args.destination_dir):
                dst.append(
                    Path.joinpath(Path(val),
                                  '%s' % Path(
                                      args.source_dir[i]).name).__str__())
        else:
            raise CPError(
                "Don't know how to process %d sources and %d destinations"
                % (len(args.source_dir), len(args.destination_dir)))

        args.dstlog = ['%s.log.txt' % i for i in dst]
        args.dstmd5 = ['%s.md5.txt' % i for i in dst]
        args.dstzip = ['%s.%s' % (i, args.extension) for i in dst]

        return args

    def chkdst(self, dstfiles):
        '''Check to see if destination files exist and decide what to
           about it'''
        process = False
        for i in dstfiles:
            if not os.path.exists(i):  # good to go
                process = True
            elif self.args.overwrite_destination is True:  # also good
                # Avoid overwriting file(s) if we did not call for it
                self.logger.warning(
                    '%s exists. overwrite_destination enabled. Overwriting!',
                    i)
                process = True
            else:
                # Avoid overwriting file(s) if we did not call for it
                self.logger.error(
                    '%s exists and overwrite_destination not set.',
                    i)
                process = False
        if process is False:
            self.logger.warning('Exiting due to exisiting files.')
            sys.exit(1)

    def getfilelist(self, path):
        '''Get a list of all files under a directory'''
        filelist = []
        self.logger.debug('Obtain list of files under %s', path)
        atime = time.perf_counter()

        for root, _, files in os.walk(path):
            for myfile in files:
                fullpath = os.path.join(root, myfile)
                filelist.append(fullpath)
        self.logger.info('Found %d files in %s. %s',
                         len(filelist), path, self.time_since(atime))
        return filelist

    @staticmethod
    def humanbytes(num):
        '''Convert a number (bytes) to human-readable bytes'''
        symbols = ('K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')
        prefix = {}
        for i, sym in enumerate(symbols):
            prefix[sym] = 1 << (i+1)*10
        for sym in reversed(symbols):
            if num >= prefix[sym]:
                return '%.1f%sB' % (num/prefix[sym], sym)
        return '%sB' % num

    def humanseconds(self, seconds):
        if seconds == 0:
            return 'inf'
        elif seconds < 60:
            return '%0.3f seconds' % seconds

        parts = []
        for unit, div in self.TIME_DURATION_UNITS:
            amount, seconds = divmod(int(seconds), div)
            if amount > 0:
                parts.append('{} {}{}'.format(
                    amount, unit, '' if amount == 1 else 's'))
        return ', '.join(parts)

    def logger_config(self):
        '''Set up class logger'''
        self.logconf = argparse.Namespace(
            consolehdlr=logging.StreamHandler(), filehdlr=None)
        logger = logging.getLogger('CruisePack')

        # pass all messages down to handlers
        logger.setLevel(logging.DEBUG)

        # console logger
        self.logconf.consolehdlr.setLevel(logging.INFO)
        self.logconf.consolehdlr.setFormatter(self.formatter)
        logger.addHandler(self.logconf.consolehdlr)

        return logger

    def logger_filehandler_add(self, dstlog):
        '''Manage logging.FileHandler. We only ever have one open at
           a time'''

        try:
            self.logconf.filehdlr = logging.FileHandler(dstlog, mode='w')
        except (FileNotFoundError, PermissionError) as err:
            raise CPError('Not able to open log file %s! %s' % (dstlog, err))

        # Add new FileHandler to logger
        self.logconf.filehdlr.setFormatter(self.formatter)
        self.logconf.filehdlr.setLevel(logging.DEBUG)
        self.logger.addHandler(self.logconf.filehdlr)

    @staticmethod
    def md5sum(path):
        '''Open a file, calculate md5sum'''
        hash_md5 = hashlib.md5()
        with open(path, 'rb') as filep:
            for chunk in iter(lambda: filep.read(4096), b""):
                hash_md5.update(chunk)
        return (path, hash_md5.hexdigest())

    def mkarchive(self, filename, files, md5file):
        '''Make a supported archive file'''
        _, tmpf = tempfile.mkstemp(dir=Path(filename).parent,
                                   prefix='%s.' % Path(filename).name)
        self.logger.debug('"%s" mode selected', self.args.extension)
        self.logger.info('Write %s (will later move to %s).', tmpf, filename)

        try:
            if self.args.extension == 'zip':
                self.mkzip(tmpf, files, md5file)
            else:
                self.mktar(tmpf, files, md5file)
        except KeyboardInterrupt:
            self.logger.warning(
                'Received keyboard interrupt. Deleting %s and quitting',
                tmpf)
            os.unlink(tmpf)
            sys.exit(2)

        self.logger.info('Wrote %s.', tmpf)

        try:
            self.logger.info('Move %s to %s.', tmpf, filename)
            os.rename(tmpf, filename)
        except FileExistsError:
            if self.args.overwrite_destination:
                self.logger.debug('%s exists. Removing.', filename)
                os.remove(filename)
                os.rename(tmpf, filename)
                return

            self.logger.error(
                '%s already exists. Quit and clean up %s.',
                filename, tmpf)
            os.remove(tmpf)
            sys.exit(3)

    def mktar(self, filename, files, md5file):
        '''Make a tarball based provided filename and list of files'''
        with tarfile.open(filename, 'w:bz2') as archive:
            archive.add(md5file)
            # Multithread add files to our archive. This speeds things
            # up, but not dramatically.
            with DummyPool(processes=self.args.proc_count) as pool:
                pool.map(archive.add, files)

    def mkzip(self, filename, files, md5file):
        '''Make a zip file based provided filename and list of files'''
        try:
            # Failover to LZMA if needed
            archive = ZipFile(filename, 'w', compression=ZIP_BZIP2)
        except NotImplementedError:
            # If we don't have LZMA nor BZIP2 capability, fail
            archive = ZipFile(filename, 'w', compression=ZIP_LZMA)
        else:
            archive.write(md5file)
            # Multithread add files to our archive. This speeds things
            # up, but not dramatically.
            # stackoverflow.com/questions/9195206/is-python-zipfile-thread-safe
            # zipfile is supposedly thread safe, but not in testing.
            # Run serially for now by limiting threads to 1.
            with DummyPool(processes=1) as pool:
                pool.map(archive.write, files)
            archive.close()

    def pack_dir(self, srcdir, dstlog, dstmd5, dstzip):
        '''Dig through a dir, md5sum every file and archive the dir'''
        atime = time.perf_counter()
        disclaimer = '(this can take a while)...'
        srcpath = Path(srcdir)

        self.chkdst([dstzip, dstlog, dstmd5])

        # Add relevant FileHandler to logging
        self.logger_filehandler_add(dstlog)
        self.logger.info('Processing directory %s', srcdir)
        self.logger.info('Start logging to %s', dstlog)

        cwd = os.getcwd()

        try:
            self.logger.info('Change directory from %s to %s',
                             cwd, srcpath.parent.__str__())
            os.chdir(srcpath.parent.__str__())
        except (FileNotFoundError, PermissionError) as err:
            self.logger.error(
                'Cannot `cd` to %s. Skip processing %s. %s',
                srcpath.parent.__str__(), srcdir, err)
            return
        else:
            filelist = self.getfilelist(srcpath.name)

            # Multiprocess file metadata operations
            with Pool(processes=self.args.proc_count) as pool:
                # Calculate sum of file sizes for every file on our list
                btime = time.perf_counter()
                self.logger.debug(
                    'Calculate total disk size used by %d files in %s %s...',
                    len(filelist), srcpath.name, disclaimer)
                bytes_used = sum(pool.map(os.path.getsize, filelist))
                self.logger.info(
                    'Total disk usage of %s: %s. %s',
                    srcpath.name, self.humanbytes(bytes_used),
                    self.time_since(btime))

                # Calculate md5sum for every file on our list
                ctime = time.perf_counter()
                self.logger.debug(
                    'Calculate md5sum on %d files in %s %s...',
                    len(filelist), srcpath.name, disclaimer)
                md5s = pool.map(self.md5sum, filelist)
                md5s.sort()

                # Save sorted list to a plaintext file
                self.logger.info(
                    'md5sum results saved to %s. %s',
                    dstmd5, self.time_since(ctime))
                with open(dstmd5, 'w') as filep:
                    filep.write('\n'.join(
                        ['{}\t{}'.format(i[1], i[0]) for i in md5s]))

            dtime = time.perf_counter()
            self.logger.info('Create %s %s', dstzip, disclaimer)
            self.mkarchive(dstzip, filelist, dstmd5)
            self.logger.info('Created %s. %s', dstzip,
                             self.time_since(dtime))

            zips = os.path.getsize(dstzip)
            self.logger.info(
                'Disk usage of %s is %s (%0.2f%% smaller than %s)', dstzip,
                self.humanbytes(zips), 100-100*(zips/bytes_used), srcdir)

        self.logger.info('Change directory from %s to %s',
                         srcpath.parent.__str__(), cwd)
        os.chdir(cwd)

        self.logger.info('Done processing %s. %s', srcdir,
                         self.time_since(atime))

        # Remove relevant FileHandler from logging
        self.logger.info('End logging to %s', dstlog)
        self.logconf.filehdlr = None

    def time_since(self, seconds):
        return 'Calculated in %s' % self.humanseconds(
            time.perf_counter() - seconds)


def main():
    '''entry point when run from commandline'''
    CruisePack()


if __name__ == "__main__":
    main()
